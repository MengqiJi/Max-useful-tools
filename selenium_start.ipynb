'''__author__:Leiwen Lin''' 
'''__maintainer__:'Leiwen Lin''' 
'''__createtime__:2018-09-14 11:02:13.844191''' 
import pandas as pd 
import re
import numpy as np
import datetime
from openpyxl.utils import get_column_letter
from lib.mywait import mywait
import sys
from selenium.webdriver.common.keys import Keys
import time
from datetime import datetime
from selenium.webdriver.support.select import Select
from selenium import webdriver
import os
from bs4 import BeautifulSoup
from lib.excel_formatter import formatter
from lib.excel_appender import appender

def js_wait():
    a = driver.find_element_by_xpath("//div[@class='appian-indicator-message']")
    while(a.get_attribute("aria-hidden") != 'true'):
        time.sleep(0.5)
        a = driver.find_element_by_xpath("//div[@class='appian-indicator-message']")
    time.sleep(1)

need_environment_var_list = ["chromedriver"]

environment_var_dict  = {}
for var_key in need_environment_var_list:
    try:
        environment_var_dict[var_key] = os.environ[var_key]
    except: 
        print(f"Please add environment variable for {var_key}, and run the APP")
        time.sleep(10)
        raise AttributeError

# 1 download MRT data

url = "https://www.fhlmc.com/enterprise_bpm/tempo/reports/view/qVK1mA"
#driverLocation = "C:\\chrome_driver\chromedriver.exe"

capabilities = { 'chromeOptions':  { 'useAutomationExtension': False}}
driver = webdriver.Chrome(environment_var_dict["chromedriver"],desired_capabilities = capabilities)
driver.get(url)
driver.maximize_window()
temp_list = []
cursor = mywait(driver).find_single_xpath("//*[@id='report-body']/div/main/div/div/div/div[6]/div[2]/div/div[2]/div/div[2]/span[3]/a")
while(True):
    js_wait()
    soup = BeautifulSoup(driver.page_source, "lxml")
    table = soup.find('table',attrs ={'class':'PagingGridLayout---table PagingGridLayout---striped PagingGridLayout---scrollable'})
    table = table.find("tbody")
    rows = table.find_all("tr")
    for row in rows:
        if len(row.find_all("p"))>0:
            temp_list.append({\
            "Change ID":row.find_all("p")[1].text,\
            "href":row.find_all("p")[1].a.get("href"),\
            #"Status": row.find_all("p")[10].text,\
            #"Entity ID": row.find_all("p")[3].text,\
            #"Entity Name": row.find_all("p")[4].text,\
            #"Project Contact": row.find_all("p")[9].text\
            })
    try:   
        #click next botton, some page do not have next botton, so we use try
        cursor = mywait(driver).find_single_xpath("//*[@id='report-body']/div/main/div/div/div/div[6]/div[2]/div/div[2]/div/div[2]/span[3]/a")
        driver.execute_script("arguments[0].click();",cursor)
    except:
        break ##if there is no next page, we break the loop.
    if not cursor.get_attribute('disabled'): ##if there is no next page, we break the loop.
        driver.execute_script("arguments[0].click();",cursor)
        js_wait()
    else:
        break

cursor = mywait(driver).find_single_xpath("//a[text()='Export Change Project Pipeline to excel']")
mywait(driver).click(cursor)
time.sleep(5)


Download_route = "C:\\Users\\" + os.environ["USERNAME"].upper() +"\\Downloads"

files = [file for file in os.listdir(Download_route) if file.find("Change_Project_Pipeline") != -1]
latest = files[0]
for file in files:
    if os.path.getctime(Download_route+'\\'+file) > os.path.getctime(Download_route+'\\'+latest):
        latest = file

total_data = pd.read_excel(Download_route+'\\'+latest)

total_data = total_data[["Change ID","Status","Proposed Deployment Date","Entity ID","Entity Name","Project Contact"]]

MRT_data = pd.merge(total_data,pd.DataFrame(temp_list))

MRT_data["Comment"]=' '

MRT_data["Proposed Deployment Date"] = MRT_data["Proposed Deployment Date"].astype("str").replace("NaT","")

# 2 filter ['Locked for Assessment','EMR QC2','Out for Approval','Approved']

filter_list = ['Locked for Assessment','EMR QC2','Out for Approval','Approved']

MRT_data = MRT_data[MRT_data["Status"].isin(filter_list)]

MRT_CHG_list = MRT_data["Change ID"].unique()

# 3 go to every single model and get data loop here

writer0 = pd.ExcelWriter("./temp data/0.xlsx", engine='xlsxwriter')
writer1 = pd.ExcelWriter("./temp data/1.xlsx", engine='xlsxwriter')
writer2 = pd.ExcelWriter("./temp data/2.xlsx", engine='xlsxwriter')
writer3 = pd.ExcelWriter("./temp data/3.xlsx", engine='xlsxwriter')
writer4 = pd.ExcelWriter("./temp data/4.xlsx", engine='xlsxwriter')
empty_df = pd.DataFrame(data = np.array([" "," "]).reshape((1,2)),columns=["No Data","N/A"])
pattern = r'-->(?P<col>.*)<!--'

MRT_data.to_excel(writer0,sheet_name="Summary",index= False)

# both.to_excel(writer, sheet_name='Both in MRT and QB',index= False)
# MRT_only.to_excel(writer, sheet_name='Only in MRT',index= False)
# QB_only.to_excel(writer, sheet_name='Only in QB',index= False)
# writer.save()

for MRT_CHG_ID in MRT_CHG_list:
    temp  = MRT_data[MRT_data["Change ID"] == MRT_CHG_ID]
    temp.to_excel(writer0,sheet_name=MRT_CHG_ID,index=False)

    driver.get(temp.href.values[0][:-7]+'_55DSWA') ## use href to reduce time
    mywait(driver,15).find_single_xpath("//*[@class='SectionLayout2---section_header']")
    time.sleep(4.5)
    js_wait()

    soup = BeautifulSoup(driver.page_source, "lxml")

    ## Model Key Assessor Assessments

    Model_Key_Assessor_Assessments  = soup.find_all('h2',attrs={"class":"SectionLayout2---section_header"})[0]

    table = Model_Key_Assessor_Assessments.parent.find('table')
    if table is not None:
        #header
        header_list = []
        headers = table.find('thead').find_all('th')
        for header in headers[1:]:
            temp = header.find_all("div")
            col_name = re.search(pattern,str(temp)).group('col')
            header_list.append(col_name)

        #tbody
        table_data = []
        rows = table.find('tbody').find_all('tr')
        for row in rows:
            row_data = []
            for td in row.find_all('td')[1:-1]:
                #print(td)
                temp = td.find("p")
                temp = re.search(pattern,str(temp))
                if temp is not None:
                    temp = temp.group('col')
                    row_data.append(temp)
                else: #empty data
                    row_data.append('')
            #check file attached?
            if row.find_all('td')[-1].find('img').get('aria-label') == '0 files':
                row_data.append('No')
            else:
                row_data.append('Yes')
            table_data.append(row_data)

        data = pd.DataFrame(table_data,columns = header_list)    
        data['Division'] = data['Division'].str.replace("&amp;","&")
        data['Assessment Type'] = data['Assessment Type'].str.replace("&amp;","&")
        data.to_excel(writer1,sheet_name=MRT_CHG_ID,index=False)
    else:        
        empty_df.to_excel(writer1,sheet_name=MRT_CHG_ID,index=False)

    ## Significant Use Assessments

    Significant_Use_Assessments  = soup.find_all('h2',attrs={"class":"SectionLayout2---section_header"})[1]

    table = Significant_Use_Assessments.parent.find('table')
    if table is not None:
        #header
        header_list = []
        headers = table.find('thead').find_all('th')
        for header in headers[1:]:
            temp = header.find_all("div")
            col_name = re.search(pattern,str(temp)).group('col')
            header_list.append(col_name)

        #tbody
        table_data = []
        rows = table.find('tbody').find_all('tr')
        for row in rows:
            row_data = []
            for td in row.find_all('td')[1:9]:
                #print(td)
                temp = td.find("p")
                temp = re.search(pattern,str(temp))
                if temp is not None:
                    temp = temp.group('col')
                    row_data.append(temp)
                else: #empty data
                    row_data.append('')
            #check file attached?
            if row.find_all('td')[9].find('img').get('aria-label') == '0 files':
                row_data.append('No')
            else:
                row_data.append('Yes')
            for td in row.find_all('td')[10:]:
                #print(td)
                temp = td.find("p")
                temp = re.search(pattern,str(temp))
                if temp is not None:
                    temp = temp.group('col')
                    row_data.append(temp)
                else: #empty data
                    row_data.append('')

            table_data.append(row_data)

        data = pd.DataFrame(table_data,columns = header_list)    
        data['Division'] = data['Division'].str.replace("&amp;","&")
        data['Assessment Type'] = data['Assessment Type'].str.replace("&amp;","&")
        data.to_excel(writer2,sheet_name=MRT_CHG_ID,index=False)
    else:        
        empty_df.to_excel(writer2,sheet_name=MRT_CHG_ID,index=False)

    # EMR Assessments

    EMR_Assessments  = soup.find_all('h2',attrs={"class":"SectionLayout2---section_header"})[2]

    table = EMR_Assessments.parent.find('table')

    if table is not None:
        #header
        header_list = []
        headers = table.find('thead').find_all('th')
        for header in headers[1:]:
            temp = header.find_all("div")
            col_name = re.search(pattern,str(temp)).group('col')
            header_list.append(col_name)
        #tbody
        table_data = []
        rows = table.find('tbody').find_all('tr')
        for row in rows:
            row_data = []
            for td in row.find_all('td')[1:7]:
                #print(td)
                temp = td.find("p")
                temp = re.search(pattern,str(temp))
                if temp is not None:
                    temp = temp.group('col')
                    row_data.append(temp)
                else: #empty data
                    row_data.append('')
            td = row.find_all('td')[7]
            if td is not None:
                row_data.append(td.text)
            else:
                row_data.append('')
            for td in row.find_all('td')[8:10]:
                #print(td)
                temp = td.find("p")
                temp = re.search(pattern,str(temp))
                if temp is not None:
                    temp = temp.group('col')
                    row_data.append(temp)
                else: #empty data
                    row_data.append('')        
            #check file attached?
            if row.find_all('td')[10].find('img').get('aria-label') == '0 files':
                row_data.append('No')
            else:
                row_data.append('Yes')
            table_data.append(row_data)

        data = pd.DataFrame(table_data,columns = header_list)    
        data['Division'] = data['Division'].str.replace("&amp;","&")
        data['Assessment Type'] = data['Assessment Type'].str.replace("&amp;","&")
        data.to_excel(writer3,sheet_name=MRT_CHG_ID,index=False)
    else:        
        empty_df.to_excel(writer3,sheet_name=MRT_CHG_ID,index=False)

    # Approvers

    Approvers  = soup.find_all('h2',attrs={"class":"SectionLayout2---section_header"})[3]
    table = Approvers.parent.find('table')

    if table is not None:
        #header
        header_list = []
        headers = table.find('thead').find_all('th')
        for header in headers[1:]:
            temp = header.find_all("div")
            col_name = re.search(pattern,str(temp)).group('col')
            header_list.append(col_name)
        #tbody
        table_data = []
        rows = table.find('tbody').find_all('tr')
        for row in rows:
            row_data = []
            for td in row.find_all('td')[1:8]:
                #print(td)
                temp = td.find("p")
                temp = re.search(pattern,str(temp))
                if temp is not None:
                    temp = temp.group('col')
                    row_data.append(temp)
                else: #empty data
                    row_data.append('')    
            #check file attached?
            if row.find_all('td')[8].find('img').get('aria-label') == '0 files':
                row_data.append('No')
            else:
                row_data.append('Yes')
            table_data.append(row_data)

        data = pd.DataFrame(table_data,columns = header_list)    
        data['Division'] = data['Division'].str.replace("&amp;","&")
        data.to_excel(writer4,sheet_name=MRT_CHG_ID,index=False)
    else:        
        empty_df.to_excel(writer4,sheet_name=MRT_CHG_ID,index=False)
  

writer0.save()
writer1.save()
writer2.save()
writer3.save()
writer4.save()
driver.quit()

# 4 formatting stuff

## format

for MRT_CHG_ID in MRT_CHG_list:
## format
    formatter(f'./temp data/{0}.xlsx',sheet_name=MRT_CHG_ID,froze_first_row=False,add_fliter= False,column_width={"A":35,"B":27,"C":30,"D":20,"F":25,"G":20,"H":20},specific_alignment_left=["F"])
    formatter(f'./temp data/{1}.xlsx',sheet_name=MRT_CHG_ID,froze_first_row=False,add_fliter= False,column_width={"A":35,"B":27,"C":30,"D":20,"F":25,"G":20,"H":20},specific_alignment_left=["H"],wrap_width=["H"])
    formatter(f'./temp data/{2}.xlsx',sheet_name=MRT_CHG_ID,froze_first_row=False,add_fliter= False,column_width={"A":35,"B":27,"C":30,"D":20,"F":25,"G":20,"H":20},specific_alignment_left=["H"],wrap_width=["H"])
    formatter(f'./temp data/{3}.xlsx',sheet_name=MRT_CHG_ID,froze_first_row=False,add_fliter= False,column_width={"A":35,"B":27,"C":30,"D":20,"F":25,"G":20,"H":20},specific_alignment_left=["H"],wrap_width=["H"])
    formatter(f'./temp data/{4}.xlsx',sheet_name=MRT_CHG_ID,froze_first_row=False,add_fliter= False,column_width={"A":35,"B":27,"C":30,"D":20,"F":25,"G":20,"H":20})
                    

for MRT_CHG_ID in MRT_CHG_list:  
## append
    appender(filename1='./temp data/0.xlsx',filename2 = './temp data/1.xlsx',H1='Model Key Assessor Assessments',sheet_name=MRT_CHG_ID)
    appender(filename1='./temp data/0.xlsx',filename2 = './temp data/2.xlsx',H1='Significant Use Assessments',sheet_name=MRT_CHG_ID)
    appender(filename1='./temp data/0.xlsx',filename2 = './temp data/3.xlsx',H1='EMR Assessments',sheet_name=MRT_CHG_ID)
    appender(filename1='./temp data/0.xlsx',filename2 = './temp data/4.xlsx',H1='Approvers',sheet_name=MRT_CHG_ID)

formatter('./temp data/0.xlsx',sheet_name = 'Summary',column_width={"C":38,"E":25},specific_alignment_left=['F'])

# 5 save file 

def digit_adj(number):
    number = str(number)
    if len(number) ==1:
        number = "0"+number
    return number

def time_format():
    time_obj = datetime.now()
    if time_obj.hour>11:
        if time_obj.hour == 12:
            return f"_{time_obj.year}_{digit_adj(time_obj.month)}_{time_obj.day}_12_{digit_adj(time_obj.minute)} PM.xlsx"
        else:
            return f"_{time_obj.year}_{digit_adj(time_obj.month)}_{time_obj.day}_{time_obj.hour%12}_{digit_adj(time_obj.minute)} PM.xlsx"
    else:
        return f"_{time_obj.year}_{digit_adj(time_obj.month)}_{time_obj.day}_{time_obj.hour}_{digit_adj(time_obj.minute)} AM.xlsx"

try:
    os.remove(f"MRT CHG Status{time_format()}")
    os.rename(".\\temp data\\0.xlsx",f"MRT CHG Status{time_format()}")
except:
    os.rename(".\\temp data\\0.xlsx", f"MRT CHG Status{time_format()}")



